[
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purpleâ€¦\nBut it is possible you first said green (donâ€™t worry if you did it is quite a common response!)\n\n\nItâ€™s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | â€” | â€” | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt getâ€™s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. ğŸŸª\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, Iâ€™ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purpleâ€¦\nBut it is possible you first said green (donâ€™t worry if you did it is quite a common response!)\n\n\nItâ€™s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | â€” | â€” | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt getâ€™s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. ğŸŸª\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, Iâ€™ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "AIâ€™s Take on â€œWhat Makes a Good Joke?â€: Can it Be Funny?\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAIâ€™s attempts at humor are put to the test as it generates jokes, revealing both its strengths in observational comedy and its limitations compared to the creativity and timing of human comedians.\n\n\n\n\n\nFeb 10, 2025\n\n\nNora Elliott\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Post1/Post1.html",
    "href": "posts/Post1/Post1.html",
    "title": "AIâ€™s Take on â€œWhat Makes a Good Joke?â€: Can it Be Funny?",
    "section": "",
    "text": "What makes a joke funny? We all know the formula: set-up, punchline, timing. But does AI understand this formula? Iâ€™ve spent plenty of time laughing at Memes and Tiktoks but could a machine do the same? So, for the sake of science (and good humor), I decided to put AI to the test and see if it could make me laugh.\nI asked our class LLM to generate jokes for me, and then I rates them on a scale of 1-10 for how funny they are\nI decided to start with a few classic joke styles: puns, one-liners, and dad jokes. AI seems to have a good grasp on these, but will they land the punchline? Here are some of the results:\n\nâ€œWhy donâ€™t skeletons fight each other? Because they donâ€™t have the guts.â€\nRating: 7/10 This oneâ€™s a classic. It hits the right balance of silly and clever. Itâ€™s a bit predictable, but I still laughed.\n\nâ€œI told my wife she was drawing her eyebrows too high. She looked surprised.â€\nRating: 6/10 A little underwhelming. I see what AI was going for, but it didnâ€™t quite have the punch I was hoping for. Itâ€™s a bit of a meh dad joke.\n\nâ€œWhatâ€™s orange and sounds like a parrot? A carrot.â€\nRating: 3/10 I get that AI loves a good pun, but this one is just so bad. It really doesnâ€™t work, AI, you tried, but this oneâ€™s a miss.\n\nNext, I thought Iâ€™d ask AI to come up with some observational humor, the kind that comments on everyday life or the weird stuff we as humans all know but never really talk about. I was curious to see if AI could pick up on little human relatable quirks like that.\n\nâ€œIsnâ€™t it funny how we can talk to Siri for hours, but when someone asks us to call someone, we freeze like weâ€™ve never made a phone call in our life?â€\nRating: 6/10 Not bad, AI. Itâ€™s relatable, and I can definitely picture myself in that awkward moment where I forget how to dial a number. Itâ€™s not groundbreaking at all, or even really funny, but its relatable and I giggled.\n\nâ€œWhy is it that every time we want to be productive, we end up on Tiktok watching puppy videos? Is it the puppy videos, or are we just procrastinating in the most adorable way possible?â€\nRating: 8/10 This one hit home as it is soooo true for me. I think we can all relate to wasting time watching cute animals when we should be working. Pretty good for an AI.\n\nâ€œWhy do we always pretend to be busy when weâ€™re actually just staring at the wall?â€\nRating: 4/10 Not funny at all, but I see the idea. Itâ€™s a good observation and an alarmingly human thing for an AI to know we often do, but the delivery couldâ€™ve been stronger.\n\nI thought Iâ€™d push AI a little further and ask it for some darker humor. I wasnâ€™t sure how it would handle this, but the results were interesting.\n\nâ€œI told my therapist I had a fear of commitment. She said, â€˜Letâ€™s schedule a session for next week, and weâ€™ll work on that.â€™â€\nRating: 6/10 This oneâ€™s self-aware. It has the dark humor vibe, but I think it could use a little more edge to land better. Still, itâ€™s got potential and is honestly better than I would expect.\n\nâ€œI once tried to run a marathon, but my body had other plans. Specifically, they were: â€˜Weâ€™re not doing this.â€™â€\nRating: 8/10 This oneâ€™s clever! It taps into a relatable struggleâ€”trying and failing to do something ambitious and the delivery is good. Not sure itâ€™s super dark but I liked it\n\nâ€œWhatâ€™s the difference between a hipster and a graveyard? The graveyard has more life.â€\nRating: 3/10 This one is just weird.\n\nAfter putting AI through its comedic paces, Iâ€™d say it can definitely be funnyâ€”sometimes. But thereâ€™s a noticeable difference between the humor of AI and the humor we get from human comedians. While both share a basic formulaâ€”set-up, punchline, timingâ€”the way AI and human comedians approach comedy is where things diverge.\nWhat makes human comedy jokes different from AI jokes?\nWhen it comes to human comedians, humor often comes with layers of personal experience, delivery, and a unique perspective on the world. Comedians like Dave Chappelle, Ali Wong, or John Mulaney have this uncanny ability to take everyday experiences and turn them into these deeply relatable, often profound, and always funny bits. Their timing is razor-sharp; they know how to pause, when to lean into a punchline, and how to give us just enough context to make the joke hit harder. Itâ€™s not just about the wordsâ€”they build tension, create expectations, and then surprise us.\nFor example, a classic Mulaney bit about being a kid is funny because of how heâ€™s able to give such a detailed picture of a childâ€™s brain, then tie that to a hilarious (yet completely believable) observation about growing up. The relatability, the self-deprecation, the storytellingâ€”it all works together. The punchline isnâ€™t just the final line; itâ€™s the entire setup that takes us to an unexpected conclusion.\nAIâ€™s humor, on the other hand, lacks that lived experience and human understanding of the world. Its jokes are more mechanical. It pulls from patterns in language and existing jokes, often replicating humor weâ€™ve already heardâ€”puns, dad jokes, and one-liners. Thereâ€™s a clear pattern to AIâ€™s jokes: it thrives on wordplay and simple observations. Take the skeleton joke from earlier: â€œWhy donâ€™t skeletons fight each other? Because they donâ€™t have the guts.â€ The humor here is straightforward, but itâ€™s almost too easy, too formulaic. The joke itself doesnâ€™t come from a personal perspective or a twist on societyâ€”itâ€™s based on a pun, which is an obvious play on words. Itâ€™s clever, but it doesnâ€™t have the kind of depth or subtext that we get from human comics who inject their own experiences into their material.\nAI doesnâ€™t seem to understand why certain jokes are funnier based on the context in which theyâ€™re told. A human comedian will know exactly how to build a joke based on the energy of the crowd, the way the nightâ€™s going, or even their own mood. AI just spits out a punchline because thatâ€™s what itâ€™s been trained to do. It doesnâ€™t feel the rhythm or energy of humorâ€”it just mimics.\nWhat makes AI jokes similar to human jokes?\nDespite the differences, thereâ€™s still something strikingly similar between AI-generated jokes and those from comedians. Both rely on patterns that people find universally funny: puns, exaggeration, and absurdity. A lot of humor is rooted in the unexpected, and AI can certainly tap into this, albeit in a more structured way. For example, the AI-generated joke about procrastination and cat videos hit the mark because itâ€™s a universal observation: people get distracted by cute animals instead of doing important things. It works because itâ€™s true. And while a comedian might add their own flair to it, AI is still able to capture the essence of what makes it relatable.\nIn a way, AIâ€™s jokes are similar to those found in early stand-up routines where the jokes are more about general observations rather than personal stories. Itâ€™s a kind of humor that exists without the depth of a specific experience, but that doesnâ€™t mean itâ€™s not funny. AI can capture the structure of humor pretty well, even if it doesnâ€™t always understand the nuance.\nWhere does AI even get its â€œsenseâ€ of humor?\nThis leads me to wonder: where does AIâ€™s humor actually come from? Is it just a bunch of algorithms trained on massive datasets of jokes? Essentially, yes. AI learns humor by analyzing a huge pool of textâ€”books, articles, websites, social media posts, and of course, jokes. It doesnâ€™t truly â€œunderstandâ€ what makes something funny in the way humans do. Itâ€™s more like AI is a super advanced â€œmimicâ€ thatâ€™s incredibly good at picking up patterns and regurgitating them. The base of what is considered funny comes from human-created content, but AI doesnâ€™t have the cultural context to make truly original humor.\nAIâ€™s jokes are built on probability. It can take certain elementsâ€”word associations, cultural references, and the structure of well-established jokesâ€”and piece them together. It doesnâ€™t know how to innovate in the way a comedian can; it just knows what worked in the past. But as funny as that is, itâ€™s also a limitation. Humor is often about breaking expectations or delivering a punchline with the right timing or cultural context. AI doesnâ€™t yet have the ability to understand the subtleties of social or emotional context in the same way humans do.\nWhat surprised me about AIâ€™s humor? What was AI better at than I expected?\nWhat really surprised me about AI, though, is how well it did at observational humor. The joke about procrastination and cat videos? I didnâ€™t expect AI to pull that off. It actually captured a very human experienceâ€”something that feels universal. The fact that AI picked up on this everyday observation and turned it into a solid joke made me realize that while itâ€™s not perfect, itâ€™s learning how to read situations and trends in a way that mirrors what makes humans laugh.\nIt also surprised me how quickly AI can generate jokes. While not every punchline lands perfectly, itâ€™s able to process information and structure humor in real-time, something that would take a human comedian far more time to write, test, and refine. AI is a quick thinker, even if it lacks the depth to really make a joke feel alive.\n\nCan AI be funny? Yes, but in a different way than a human comedian. It can replicate basic humor patterns and structure jokes, but it doesnâ€™t yet have the personal touch or nuanced understanding of why something is funny in a given context. The humor is still very much surface-level, but that doesnâ€™t mean it canâ€™t make you smile. Itâ€™s a fun experiment, but for now, human comedians still have the edge when it comes to creativity, timing, and injecting the rich context that makes humor truly memorable.\nWould I trust AI to headline my comedy night? Probably not. But was it funnier than I expected? Yea it surprised me."
  }
]