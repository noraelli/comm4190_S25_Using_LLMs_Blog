[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "AI’s Take on “What Makes a Good Joke?”: Can it Be Funny?\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAI’s attempts at humor are put to the test as it generates jokes, revealing both its strengths in observational comedy and its limitations compared to the creativity and timing of human comedians.\n\n\n\n\n\nFeb 10, 2025\n\n\nNora Elliott\n\n\n\n\n\n\n\n\n\n\n\n\nAI vs. Human Chef: Can A Chat Bot Really Help You Cook Dinner?\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nNLPs\n\n\n\nThis blog post explores how an AI-powered recipe generator can suggest meal ideas based on available ingredients and compares its capabilities to the creativity and intuition of a human chef.\n\n\n\n\n\nFeb 10, 2025\n\n\nNora Elliott\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Post1/Post1.html",
    "href": "posts/Post1/Post1.html",
    "title": "AI’s Take on “What Makes a Good Joke?”: Can it Be Funny?",
    "section": "",
    "text": "We all know the formula: set-up, punchline, timing. But does AI understand this formula? I’ve spent plenty of time laughing at Memes and Tiktoks but could a machine do the same? So, for the sake of science (and good humor), I decided to put AI to the test and see if it could make me laugh.\nI asked our class LLM to generate jokes for me, and then I rates them on a scale of 1-10 for how funny they are"
  },
  {
    "objectID": "posts/Post1/Post1.html#what-makes-human-comedy-jokes-different-from-ai-jokes",
    "href": "posts/Post1/Post1.html#what-makes-human-comedy-jokes-different-from-ai-jokes",
    "title": "AI’s Take on “What Makes a Good Joke?”: Can it Be Funny?",
    "section": "What makes human comedy jokes different from AI jokes?",
    "text": "What makes human comedy jokes different from AI jokes?\nWhen it comes to human comedians, humor often comes with layers of personal experience, delivery, and a unique perspective on the world. Comedians like Dave Chappelle, Ali Wong, or John Mulaney have this uncanny ability to take everyday experiences and turn them into these deeply relatable, often profound, and always funny bits. Their timing is razor-sharp; they know how to pause, when to lean into a punchline, and how to give us just enough context to make the joke hit harder. It’s not just about the words—they build tension, create expectations, and then surprise us.\nFor example, a classic Mulaney bit about being a kid is funny because of how he’s able to give such a detailed picture of a child’s brain, then tie that to a hilarious (yet completely believable) observation about growing up. The relatability, the self-deprecation, the storytelling—it all works together. The punchline isn’t just the final line; it’s the entire setup that takes us to an unexpected conclusion.\nAI’s humor, on the other hand, lacks that lived experience and human understanding of the world. Its jokes are more mechanical. It pulls from patterns in language and existing jokes, often replicating humor we’ve already heard—puns, dad jokes, and one-liners. There’s a clear pattern to AI’s jokes: it thrives on wordplay and simple observations. Take the skeleton joke from earlier: “Why don’t skeletons fight each other? Because they don’t have the guts.” The humor here is straightforward, but it’s almost too easy, too formulaic. The joke itself doesn’t come from a personal perspective or a twist on society—it’s based on a pun, which is an obvious play on words. It’s clever, but it doesn’t have the kind of depth or subtext that we get from human comics who inject their own experiences into their material.\nAI doesn’t seem to understand why certain jokes are funnier based on the context in which they’re told. A human comedian will know exactly how to build a joke based on the energy of the crowd, the way the night’s going, or even their own mood. AI just spits out a punchline because that’s what it’s been trained to do. It doesn’t feel the rhythm or energy of humor—it just mimics."
  },
  {
    "objectID": "posts/Post1/Post1.html#what-makes-ai-jokes-similar-to-human-jokes",
    "href": "posts/Post1/Post1.html#what-makes-ai-jokes-similar-to-human-jokes",
    "title": "AI’s Take on “What Makes a Good Joke?”: Can it Be Funny?",
    "section": "What makes AI jokes similar to human jokes?",
    "text": "What makes AI jokes similar to human jokes?\n (The first ever AI powered stand up show)\nDespite the differences, there’s still something strikingly similar between AI-generated jokes and those from comedians. Both rely on patterns that people find universally funny: puns, exaggeration, and absurdity. A lot of humor is rooted in the unexpected, and AI can certainly tap into this, albeit in a more structured way. For example, the AI-generated joke about procrastination and cat videos hit the mark because it’s a universal observation: people get distracted by cute animals instead of doing important things. It works because it’s true. And while a comedian might add their own flair to it, AI is still able to capture the essence of what makes it relatable.\nIn a way, AI’s jokes are similar to those found in early stand-up routines where the jokes are more about general observations rather than personal stories. It’s a kind of humor that exists without the depth of a specific experience, but that doesn’t mean it’s not funny. AI can capture the structure of humor pretty well, even if it doesn’t always understand the nuance."
  },
  {
    "objectID": "posts/Post1/Post1.html#where-does-ai-even-get-its-sense-of-humor",
    "href": "posts/Post1/Post1.html#where-does-ai-even-get-its-sense-of-humor",
    "title": "AI’s Take on “What Makes a Good Joke?”: Can it Be Funny?",
    "section": "Where does AI even get its “sense” of humor?",
    "text": "Where does AI even get its “sense” of humor?\nThis leads me to wonder: where does AI’s humor actually come from? Is it just a bunch of algorithms trained on massive datasets of jokes? Essentially, yes. AI learns humor by analyzing a huge pool of text—books, articles, websites, social media posts, and of course, jokes. It doesn’t truly “understand” what makes something funny in the way humans do. It’s more like AI is a super advanced “mimic” that’s incredibly good at picking up patterns and regurgitating them. The base of what is considered funny comes from human-created content, but AI doesn’t have the cultural context to make truly original humor.\nAI’s jokes are built on probability. It can take certain elements—word associations, cultural references, and the structure of well-established jokes—and piece them together. It doesn’t know how to innovate in the way a comedian can; it just knows what worked in the past. But as funny as that is, it’s also a limitation. Humor is often about breaking expectations or delivering a punchline with the right timing or cultural context. AI doesn’t yet have the ability to understand the subtleties of social or emotional context in the same way humans do."
  },
  {
    "objectID": "posts/Post1/Post1.html#what-surprised-me-about-ais-humor-what-was-ai-better-at-than-i-expected",
    "href": "posts/Post1/Post1.html#what-surprised-me-about-ais-humor-what-was-ai-better-at-than-i-expected",
    "title": "AI’s Take on “What Makes a Good Joke?”: Can it Be Funny?",
    "section": "What surprised me about AI’s humor? What was AI better at than I expected?",
    "text": "What surprised me about AI’s humor? What was AI better at than I expected?\nWhat really surprised me about AI, though, is how well it did at observational humor. The joke about procrastination and cat videos? I didn’t expect AI to pull that off. It actually captured a very human experience—something that feels universal. The fact that AI picked up on this everyday observation and turned it into a solid joke made me realize that while it’s not perfect, it’s learning how to read situations and trends in a way that mirrors what makes humans laugh.\nIt also surprised me how quickly AI can generate jokes. While not every punchline lands perfectly, it’s able to process information and structure humor in real-time, something that would take a human comedian far more time to write, test, and refine. AI is a quick thinker, even if it lacks the depth to really make a joke feel alive.\n\n\nCan AI be funny? Yes, but in a different way than a human comedian.\nIt can replicate basic humor patterns and structure jokes, but it doesn’t yet have the personal touch or nuanced understanding of why something is funny in a given context. The humor is still very much surface-level, but that doesn’t mean it can’t make you smile. It’s a fun experiment, but for now, human comedians still have the edge when it comes to creativity, timing, and injecting the rich context that makes humor truly memorable.\nWould I trust AI to headline my comedy night? Probably not. But was it funnier than I expected? Yea it surprised me."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/Post1/Post2.html",
    "href": "posts/Post1/Post2.html",
    "title": "AI vs. Human Chef: Can A Chat Bot Really Help You Cook Dinner?",
    "section": "",
    "text": "Ever stand in front of your fridge, staring at a bunch of random ingredients, trying to figure out what to make for dinner? Well, what if AI could help with that? I decided to test out an AI-powered recipe generator to see what it could come up with based on the contents of my fridge. I inputted a list of common ingredients—leftover chicken, bell peppers, onions, spinach, and some pantry staples—and let the AI work its magic. Here are some of the dishes it suggested, and how I think they’d turn out:"
  },
  {
    "objectID": "posts/Post1/Post2.html#ai-vs.-human-chef",
    "href": "posts/Post1/Post2.html#ai-vs.-human-chef",
    "title": "AI vs. Human Chef: Can A Chat Bot Really Help You Cook Dinner?",
    "section": "AI vs. Human Chef",
    "text": "AI vs. Human Chef\nA human chef’s creativity, experience, and ability to understand the nuances of flavor go far beyond what any AI could currently replicate. When a chef enters the kitchen, they rely on more than just a list of ingredients. They have the ability to sense balance—what flavors need to be adjusted, what textures will complement each other, or even how the dish might be presented to enhance the overall experience. A human chef might intuitively add a splash of lemon juice to brighten up a dish or adjust the seasoning based on how the ingredients come together while cooking. On the other hand, AI lacks this kind of sensory feedback. It doesn’t have taste buds, nor does it have years of experience fine-tuning recipes and techniques. It works by drawing from patterns in the data it’s been trained on—recipes from cookbooks, food blogs, cooking websites, and countless other sources. This means that while AI can come up with perfectly acceptable dishes based on what ingredients are available, it doesn’t understand how those dishes will feel once they’re put together. There’s no personal touch in its cooking, no instinct to elevate a dish by making a tiny change, like adding a pinch of a specific spice at the right moment.\n\n\n\n43ee1cafca2f947f0be0d94aeff0fc26-chef-cartoon-profession.png"
  },
  {
    "objectID": "posts/Post1/Post2.html#what-surprised-me",
    "href": "posts/Post1/Post2.html#what-surprised-me",
    "title": "AI vs. Human Chef: Can A Chat Bot Really Help You Cook Dinner?",
    "section": "What surprised me",
    "text": "What surprised me\nWhat surprised me most was how well the AI was able to suggest meals using basic ingredients. It didn’t just throw out a random combination, but instead, it took common recipe structures and applied them intelligently to the ingredients I had. For example, the stuffed bell peppers seemed like a creative take, and I honestly didn’t expect the AI to come up with such a thoughtful idea from what I gave it. It showed me that, while AI isn’t going to be a Michelin-starred chef anytime soon, it’s very capable of proposing ideas that work within the limitations of available ingredients. What’s more, I was also surprised by how well the AI captured the idea of creating balanced meals. It recognized that chicken, veggies, and cheese are often used together and suggested combinations that made sense. The dishes, while basic, didn’t seem off-putting or odd, which is impressive given the AI doesn’t actually “taste” the food. It uses its vast database of recipe knowledge to predict what flavors and ingredients tend to complement each other based on data rather than experience."
  },
  {
    "objectID": "posts/Post1/Post2.html#where-does-ai-get-its-knowledge-of-what-tastes-good",
    "href": "posts/Post1/Post2.html#where-does-ai-get-its-knowledge-of-what-tastes-good",
    "title": "AI vs. Human Chef: Can A Chat Bot Really Help You Cook Dinner?",
    "section": "Where does AI get its knowledge of what tastes good?",
    "text": "Where does AI get its knowledge of what tastes good?\nAI’s knowledge comes from its massive training on a wide range of data—especially culinary resources like recipe websites, cookbooks, blogs, and reviews. It doesn’t have a direct understanding of taste like a chef does. Instead, it’s more of a data-processing system that identifies patterns. For example, it can learn that chicken and garlic often go together in Mediterranean cuisine or that spinach is frequently paired with cheese in pasta dishes. It’s pulling from what’s worked before, from both common dishes and the success of those dishes based on reviews and feedback, to make predictions about what will taste good. However, without the human element—those sensory moments when a chef adjusts their dish based on what’s in front of them—AI can’t truly “know” what would taste good beyond the parameters of established culinary patterns. The recipes it creates aren’t born from experimentation or the chef’s personal knowledge—they’re the result of statistical analysis of what’s most likely to work.\n\nThe AI-powered recipe generator was surprisingly capable of offering up simple, quick meals that were logical and would likely be enjoyable to eat, though they might lack the depth and creativity a human chef could bring to the table.\nIt can certainly be helpful when you’re in a rush, especially when you’re staring into your fridge and feeling uninspired. But, when it comes to really elevating flavors or taking a meal to the next level, a human chef’s touch, based on expertise and an understanding of how flavors develop, still holds the upper hand.\nAI’s ability to come up with functional meal ideas shows that it can be a useful kitchen assistant, especially for beginners or those who need to work with limited ingredients. However, when it comes to the magic of cooking and creating something memorable, that’s where a human chef still shines.\n\n\n\n360_F_416275833_h6zdOY2YqTq0VwAhmTvrANehceucH6xp.jpg\n\n\n\n\nWould I trust AI to cook me the most memorable meal of my life? Probably not. But it can for sure be helpful in everyday recipe planning!"
  }
]